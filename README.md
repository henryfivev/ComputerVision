# SYSU 模式识别与计算机视觉

中山大学李冠彬老师 2023春

## 一、概述



## 二、像素与滤波器



## 三、边缘检测

### Sobel过滤器



### Canny过滤器



### LoG算法

Laplacian of Gaussian

## 四、特征检测

### 1、直线检测

#### 霍夫变换

Hough transform

#### RANSAC

（直线，园。。。）

随机选两个点，确定一条直线，看看有多少点落在该直线上

#### 不变性



### 2、角点检测

#### Moravec

略

#### Harris角点检测器

##### 原理

窗口在角点上按任意角度移动时，窗口的灰度图都会有明显的变化。

窗口滑动分别按x和y方向移动[u, v]后，灰度的变化为

$$
E(u,v) = \sum_{x,y}w(x,y) { [I(x+u,y+v)-I(x,y)]^2}
$$
${w(x,y)}$是窗口函数，二维的滤波器。

${I(x+u,y+v)}$和${I(x,y)}$分别是平移前和平移后的窗口灰度图。

再用泰勒公式${f(x+u,y+v) = f(x,y)+uf_x(x,y)+vf_y(x,y)}$ 简化为

$$
E(x,y)=[u,v]M{ \left[
 \begin{matrix}
   u\\v
  \end{matrix}
  \right]}
$$

$$
M=\sum_{x,y}w(x,y){ \left[
 \begin{matrix}
   I_x^2&I_xI_y\\
   I_xI_y&I_y^2
  \end{matrix}
  \right]}
$$

${I_x}$和${I_y}$为x和y方向的梯度值，可以用Sobel进行计算。

接着${M}$可以用实对称矩阵对角化进一步化简：

$$
M=R^{-1}
{\left[
 \begin{matrix}
   \lambda_1&0\\
   0&\lambda_2
  \end{matrix}
  \right] }
  R
$$
最后根据${\lambda_1}$和${\lambda_2}$计算角点响应函数R：

$$
R={\lambda_1\lambda_2}-k(\lambda_1+\lambda_2)^2
$$
k为经验常数，一般取0.04-0.06。

当R很小且小于threshold时，认为是平坦区域；

当R<0且R<threshold时，认为是边缘；

当R>0且R>threshold时，认为是角点。

##### 步骤

1. 计算${I_x}$和${I_y}$
2. 计算${I_xI_y}$
3. 把${w(x,y)}$，一般是高斯滤波器，应用到${I_x}$、${I_y}$和${I_xI_y}$上，计算$M$矩阵
4. 计算响应值R

##### 特性

平移不变性

旋转不变性

不满足尺度不变性

#### 高斯差分滤波器（DoG）

尺度不变性

## 五、特征描述子

### SIFT描述子



### HOG描述子



## 六、图像缩放

### Seam Carving

能量图

算法优化

### 应用

缩小&放大

去除物体

视频中应用

## 七、图像分割与聚类

超像素

### Agglomerate Clustering

层次聚类的一种

Gestalt理论

### K-means
步骤：
1. 随机选择k个样本作为初始聚类中心a={a1,a2,…ak}；
2. 针对数据集中每个样本xi计算它到k个聚类中心的距离并将其分到距离最小的聚类中心所对应的类中；
3. 重新计算每个聚类中心ai，使其等于该聚类中所有样本的均值；
4. 重复执行第2步和第3步，直到聚类结果不再发生变化或达到预定的迭代次数为止。

### Mean-shift Clustering



## 八、降维

### 奇异值分解



### 主成分分析

降低数据的维度并发现数据中的主要模式和结构

如果数据具有非线性结构，PCA可能无法有效地捕捉到关键特征

#### 原理

PCA的主要思想是将原始数据投影到一个新的坐标系中，使得投影后的数据具有最大的方差。通过选择最大方差的主成分，我们可以在保留尽可能多信息的同时减少数据的维度。这有助于去除数据中的冗余信息，并揭示数据中的主要模式和结构。

#### 步骤

1. 数据归一化：为了消除不同特征的量纲差异，通常对数据进行归一化处理，使得每个特征的均值为0，方差为1。
2. 计算协方差矩阵：根据归一化后的数据，计算协方差矩阵。协方差矩阵反映了不同特征之间的相关性。
3. 特征值分解：对协方差矩阵进行特征值分解，得到特征值和对应的特征向量。特征值表示了每个主成分的方差，特征向量表示了每个主成分的方向。
4. 选择主成分：按照特征值的大小，选择最大的前n个特征值对应的特征向量作为主成分，其中n是我们希望保留的维度数量。
5. 数据映射：将原始数据通过选定的主成分进行线性变换，得到低维表示的数据。

### 图像压缩



## 九、人脸识别



## 十、视觉词袋


## 十一、目标检测

## 十二、视觉识别

## 十三、Motion

## 十四、Tracking

## 十五、神经网络

## 十六、图像分类

## 十七、正则化

## 十八、深度学习基础