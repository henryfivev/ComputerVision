# SYSU 模式识别与计算机视觉

中山大学李冠彬老师 2023春

## 一、概述



## 二、像素与滤波器



## 三、边缘检测

### Sobel过滤器



### Canny过滤器



### LoG算法

Laplacian of Gaussian

## 四、特征检测

### 1、直线检测

#### Hough变换

不仅限于直线和圆，许多形状都能检测。

##### 原理

变换到参数空间。

例如图像中的直线y=ax+b，y和x是变量，参数空间中a和b是变量。直线上的各个点对应的a和b是相同的，在参数空间中表现为多条直线的交点。

#### RANSAC

##### 步骤

1. 选取一组点（直线2个点）
2. 计算模型
3. 计算局内点
4. 根据局内点重新计算

##### 图像拼接中的作用

https://zhuanlan.zhihu.com/p/338654260

https://blog.csdn.net/ak47fourier/article/details/80343372

假设img1和img2上都找到了n个关键点，并且一一对应。那么在sift描述子上选取一组点，计算出一个变换矩阵（模型）。如果img1中的关键点n1能够变换为img2中的n2关键点，则将该描述子纳入局内点。

#### 不变性

##### 动机

图像匹配

### 2、角点检测

#### Moravec

略

#### Harris角点检测器

##### 原理

窗口在角点上按任意角度移动时，窗口的灰度图都会有明显的变化。

窗口滑动分别按x和y方向移动[u, v]后，灰度的变化为

$$
E(u,v) = \sum_{x,y}w(x,y) { [I(x+u,y+v)-I(x,y)]^2}
$$
${w(x,y)}$是窗口函数，二维的滤波器。

${I(x+u,y+v)}$和${I(x,y)}$分别是平移前和平移后的窗口灰度图。

再用泰勒公式${f(x+u,y+v) = f(x,y)+uf_x(x,y)+vf_y(x,y)}$ 简化为

$$
E(x,y)=[u,v]M{ \left[
 \begin{matrix}
   u\\v
  \end{matrix}
  \right]}
$$

$$
M=\sum_{x,y}w(x,y){ \left[
 \begin{matrix}
   I_x^2&I_xI_y\\
   I_xI_y&I_y^2
  \end{matrix}
  \right]}
$$

${I_x}$和${I_y}$为x和y方向的梯度值，可以用Sobel进行计算。

接着${M}$可以用实对称矩阵对角化进一步化简：

$$
M=R^{-1}
{\left[
 \begin{matrix}
   \lambda_1&0\\
   0&\lambda_2
  \end{matrix}
  \right] }
  R
$$
最后根据${\lambda_1}$和${\lambda_2}$计算角点响应函数R：

$$
R={\lambda_1\lambda_2}-k(\lambda_1+\lambda_2)^2
$$
k为经验常数，一般取0.04-0.06。

当R很小且小于threshold时，认为是平坦区域；

当R<0且R<threshold时，认为是边缘；

当R>0且R>threshold时，认为是角点。

##### 步骤

1. 计算${I_x}$和${I_y}$
2. 计算${I_xI_y}$
3. 把${w(x,y)}$，一般是高斯滤波器，应用到${I_x}$、${I_y}$和${I_xI_y}$上，计算$M$矩阵
4. 计算响应值R

##### 特性

平移不变性

旋转不变性

不满足尺度不变性

#### 高斯差分滤波器（DoG）

尺度不变性

## 五、特征描述子

### SIFT描述子

[特征提取算法（3）——SIFT特征提取算子 - keepgoing18 - 博客园 (cnblogs.com)](https://www.cnblogs.com/pacino12134/p/11368558.html)

#### 步骤

1. 找到关键点
2. 将关键点图像划分为4x4的小块，再将小块划分为4x4的小小块
3. 对于每个小小块，计算其内部的梯度幅值和梯度方向，然后将梯度方向分成8个方向，每个方向覆盖45度，并将该方向上的梯度幅值累加起来，每个小块拥有8个方向的方向向量。
4. 把每个小块的方向向量组成一个8维向量
5. 所有8维向量拼接起来得到一个128维向量，这就是sift描述子

### HOG描述子

[HOG特征提取原理及实现 - 无趣的鱼 - 博客园 (cnblogs.com)](https://www.cnblogs.com/urglyfish/articles/12417343.html)

#### 步骤

1. 预处理：灰度化，gamma矫正
2. 将图像划分为窗口(window)，窗口划分为块(block)，块划分为细胞(cell)
3. 归一化
4. 计算梯度：像素点计算梯度，判断所属方向区间（9个方向）
5. 细胞内构建梯度直方图：像素点梯度加权统计
6. 块内梯度直方图归一化：假设一个块有4个细胞，每个细胞9维向量，共4个9维向量
7. 拼接生成HOG特征向量

窗口特征向量维度：窗口64x128，块8x8，细胞4x4，那么一个窗口有7x15个块，一个块有4个细胞，那么一个块就有4个9维向量，一个窗口就有7x15x4x9=3780维度的向量。

梯度只算180度，即将180度划分为9个方向，而不是360度，因为完全相反的梯度被认为是同一个梯度方向。

## 六、图像缩放

### Seam Carving

能量图

算法优化

### 应用

缩小&放大

去除物体

视频中应用

## 七、图像分割与聚类

超像素

### Agglomerate Clustering

层次聚类的一种

Gestalt理论

### K-means
步骤：
1. 随机选择k个样本作为初始聚类中心a={a1,a2,…ak}；
2. 针对数据集中每个样本xi计算它到k个聚类中心的距离并将其分到距离最小的聚类中心所对应的类中；
3. 重新计算每个聚类中心ai，使其等于该聚类中所有样本的均值；
4. 重复执行第2步和第3步，直到聚类结果不再发生变化或达到预定的迭代次数为止。

### Mean-shift Clustering



## 八、降维

### 奇异值分解



### 主成分分析

降低数据的维度并发现数据中的主要模式和结构

如果数据具有非线性结构，PCA可能无法有效地捕捉到关键特征

#### 原理

PCA的主要思想是将原始数据投影到一个新的坐标系中，使得投影后的数据具有最大的方差。通过选择最大方差的主成分，我们可以在保留尽可能多信息的同时减少数据的维度。这有助于去除数据中的冗余信息，并揭示数据中的主要模式和结构。

#### 步骤

1. 数据归一化：为了消除不同特征的量纲差异，通常对数据进行归一化处理，使得每个特征的均值为0，方差为1。
2. 计算协方差矩阵：根据归一化后的数据，计算协方差矩阵。协方差矩阵反映了不同特征之间的相关性。
3. 特征值分解：对协方差矩阵进行特征值分解，得到特征值和对应的特征向量。特征值表示了每个主成分的方差，特征向量表示了每个主成分的方向。
4. 选择主成分：按照特征值的大小，选择最大的前n个特征值对应的特征向量作为主成分，其中n是我们希望保留的维度数量。
5. 数据映射：将原始数据通过选定的主成分进行线性变换，得到低维表示的数据。

### 图像压缩



## 九、人脸识别



## 十、视觉词袋


## 十一、目标检测

## 十二、视觉识别

## 十三、Motion

## 十四、Tracking

## 十五、神经网络

## 十六、图像分类

## 十七、正则化

## 十八、深度学习基础

多层感知机

前向传播和反向传播

梯度下降

cnn训练过程

resnet

图像分类、物体检测和语义分割

## 十九、CNN进行图像分类

输入输出计算

参数计算

## 二十、卷积神经网络架构

batch norm：一批样本的一个通道

layer norm：一个样本的所有通道

instance norm：一个样本的一个通道

